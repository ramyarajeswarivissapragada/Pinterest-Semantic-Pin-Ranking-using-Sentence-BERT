# ğŸ“Œ Pinterest Semantic Ranking

This project builds an **end-to-end semantic ranking system** that simulates Pinterestâ€™s content discovery engine using NLP. Given a user query like `"boho wedding decor"` or `"kitchen storage hacks"`, the app returns the **top influencer pins** ranked by **semantic similarity**, not just keyword overlap.

Built with Sentence-BERT, CrossEncoder, and Streamlit, this system reimagines how Pinterest-style search can surface more relevant and engaging content.

---

## ğŸ¯ Problem Statement

How do we help users find **relevant**, **engaging**, and **diverse** Pinterest pins based on short natural language queries?

- Traditional keyword search often fails due to vocabulary mismatch or noisy descriptions.
- Pinterest users type vague or aesthetic-heavy queries (e.g., "cozy chic corner") that require **semantic understanding**.
- Our goal: **Rank influencer pins** by relevance, while also considering **popularity (repin count)**.

---

## ğŸ› ï¸ Tech Stack

| Component               | Description                                              |
|------------------------|----------------------------------------------------------|
| `Sentence-BERT`        | Converts pin text and queries into vector embeddings     |
| `Cosine Similarity`    | Measures semantic closeness between query and pin text   |
| `CrossEncoder (MiniLM)`| Jointly encodes queryâ€“pin pairs for deeper reranking     |
| `Streamlit`            | Interactive app UI with sliders and input box            |
| `scikit-learn`         | Score blending and MinMax scaling                        |

---

## ğŸ“¦ Dataset

**Dataset**: *Top Pinterest Influencers â€“ A Snapshot of Popularity & Engagement*  
**Rows**: 5,000 â†’ 2,428 (after cleaning)  
**Columns**:
- `id`
- `title`
- `description`
- `repin_count`

**Preprocessing**:
- Combined `title` and `description` â†’ `text`
- Dropped missing or very short rows
- Filtered non-English and emoji-only pins
- Converted `repin_count` to integers
- Saved outputs:
  - `cleaned_pins.csv`
  - `embeddings.npy`

---

## ğŸ” Ranking Pipeline

### â¤ Stage 1: Sentence-BERT + Cosine Similarity

1. Embed user query and all pin texts
2. Compute cosine similarity
3. Filter out low-relevance pins (threshold slider)
4. Blend semantic similarity and pin popularity using a tunable `Î±` value:

```python
final_score = Î± * similarity + (1 - Î±) * log(repin_count + 1)


### Stage 2: CrossEncoder Reranking (Optional)
Take top 30 candidate pins from Stage 1

Use a pretrained CrossEncoder to rescore each (query, pin) pair jointly

Scale CrossEncoder scores to [0, 1]

Combine with log-repin counts for final score:

python
Copy
Edit
final_score = Î± * scaled_cross_score + (1 - Î±) * log1p(repin_count)
ğŸ“Œ You can toggle this reranking in the Streamlit UI.

ğŸ§ª Evaluation Summary
We manually tested 20 diverse queries using:

âœ… CrossEncoder reranking

âš™ï¸ top_k=5, threshold=0.4, alpha=0.7 (defaults)

âš¡ Highlights
Precision@3 â‰ˆ 85%

False positives reduced (e.g., Doja Cat filtered out)

Some queries returned <5 results due to semantic filtering

Top-ranked pins had 2â€“3Ã— more repins than average

ğŸ“‚ For detailed results â†’ evaluation.md

ğŸ›ï¸ Streamlit App Features
ğŸ” Text input box

ğŸ”¢ Top-K slider

ğŸ¯ Similarity threshold slider

âš–ï¸ Similarity vs Popularity blending (Î±)

âœ… CrossEncoder reranking toggle

ğŸ“Š Outputs: Pin Text, Repin Count, Relevance Score, Cross Score

